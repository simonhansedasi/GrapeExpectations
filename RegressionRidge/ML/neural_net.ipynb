{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6609d0b0-a697-4538-9e60-bb2de3826c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cadbd7a7-ceda-4995-87a7-2fb9711166e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot_ndvi.pkl\n",
      "weather_25_clipped.pkl\n",
      "df_savi.pkl\n",
      "plot_elev_features.pkl\n",
      "df_ndwi.pkl\n",
      "df_ndvi_rendvi.pkl\n",
      "df_evi.pkl\n",
      "ndvi_raw_2025.pkl\n",
      "DEM\n",
      "plot_features.pkl\n",
      "df_mcari2.pkl\n",
      "ndvi_2025.pkl\n",
      "df_2025.pkl\n",
      "PRISM\n",
      "df.pkl\n",
      "plot_ndvi_filtered.pkl\n",
      "plot_ndvi_filtered_2025.pkl\n",
      "polygons\n",
      "ndvi\n",
      "plot_ndvi_2025.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "data_dir = '../data'\n",
    "for file in os.listdir(data_dir):\n",
    "    if os.path.isdir(file):\n",
    "        continue\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d99d1f-dc87-4ed5-b657-9e781ce218e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndvi_smooth_mean_28</th>\n",
       "      <th>ndvi_smooth_mean_29</th>\n",
       "      <th>ndvi_smooth_mean_30</th>\n",
       "      <th>ndvi_smooth_mean_31</th>\n",
       "      <th>ndvi_smooth_mean_32</th>\n",
       "      <th>ndvi_smooth_mean_33</th>\n",
       "      <th>ndvi_smooth_mean_34</th>\n",
       "      <th>ndvi_smooth_mean_35</th>\n",
       "      <th>ndvi_smooth_mean_36</th>\n",
       "      <th>ndvi_smooth_mean_37</th>\n",
       "      <th>...</th>\n",
       "      <th>ppt_week_sum_33_pro_curve_mean</th>\n",
       "      <th>ppt_week_sum_33_plan_curve_mean</th>\n",
       "      <th>ppt_week_sum_34_slope_rad_mean_x</th>\n",
       "      <th>ppt_week_sum_34_slope_rad_mean_y</th>\n",
       "      <th>ppt_week_sum_34_pro_curve_mean</th>\n",
       "      <th>ppt_week_sum_34_plan_curve_mean</th>\n",
       "      <th>ppt_week_sum_35_slope_rad_mean_x</th>\n",
       "      <th>ppt_week_sum_35_slope_rad_mean_y</th>\n",
       "      <th>ppt_week_sum_35_pro_curve_mean</th>\n",
       "      <th>ppt_week_sum_35_plan_curve_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.492664</td>\n",
       "      <td>0.506519</td>\n",
       "      <td>0.514245</td>\n",
       "      <td>0.502695</td>\n",
       "      <td>0.492293</td>\n",
       "      <td>0.480777</td>\n",
       "      <td>0.470647</td>\n",
       "      <td>0.469949</td>\n",
       "      <td>0.470567</td>\n",
       "      <td>0.470058</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.523357</td>\n",
       "      <td>0.511972</td>\n",
       "      <td>0.502959</td>\n",
       "      <td>0.499854</td>\n",
       "      <td>0.500775</td>\n",
       "      <td>0.498219</td>\n",
       "      <td>0.481144</td>\n",
       "      <td>0.452316</td>\n",
       "      <td>0.436442</td>\n",
       "      <td>0.417638</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000814</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.479728</td>\n",
       "      <td>0.459045</td>\n",
       "      <td>0.450454</td>\n",
       "      <td>0.435791</td>\n",
       "      <td>0.426768</td>\n",
       "      <td>0.434232</td>\n",
       "      <td>0.443162</td>\n",
       "      <td>0.444332</td>\n",
       "      <td>0.418934</td>\n",
       "      <td>0.410383</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.066582</td>\n",
       "      <td>0.01339</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.400038</td>\n",
       "      <td>0.397093</td>\n",
       "      <td>0.390670</td>\n",
       "      <td>0.385279</td>\n",
       "      <td>0.386711</td>\n",
       "      <td>0.390665</td>\n",
       "      <td>0.392255</td>\n",
       "      <td>0.377887</td>\n",
       "      <td>0.350932</td>\n",
       "      <td>0.340456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000965</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>-0.272692</td>\n",
       "      <td>0.054842</td>\n",
       "      <td>-0.000713</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.354022</td>\n",
       "      <td>0.346084</td>\n",
       "      <td>0.339436</td>\n",
       "      <td>0.339607</td>\n",
       "      <td>0.347509</td>\n",
       "      <td>0.355982</td>\n",
       "      <td>0.364158</td>\n",
       "      <td>0.363430</td>\n",
       "      <td>0.349029</td>\n",
       "      <td>0.329171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0.418890</td>\n",
       "      <td>0.403456</td>\n",
       "      <td>0.391616</td>\n",
       "      <td>0.388964</td>\n",
       "      <td>0.389758</td>\n",
       "      <td>0.392774</td>\n",
       "      <td>0.397628</td>\n",
       "      <td>0.399128</td>\n",
       "      <td>0.386335</td>\n",
       "      <td>0.361557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0.413986</td>\n",
       "      <td>0.405636</td>\n",
       "      <td>0.403766</td>\n",
       "      <td>0.401218</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.403209</td>\n",
       "      <td>0.403717</td>\n",
       "      <td>0.403379</td>\n",
       "      <td>0.400121</td>\n",
       "      <td>0.393150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0.569267</td>\n",
       "      <td>0.571609</td>\n",
       "      <td>0.564436</td>\n",
       "      <td>0.559349</td>\n",
       "      <td>0.551364</td>\n",
       "      <td>0.547924</td>\n",
       "      <td>0.544081</td>\n",
       "      <td>0.542496</td>\n",
       "      <td>0.539937</td>\n",
       "      <td>0.541718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0.556083</td>\n",
       "      <td>0.538577</td>\n",
       "      <td>0.521227</td>\n",
       "      <td>0.517825</td>\n",
       "      <td>0.516809</td>\n",
       "      <td>0.517540</td>\n",
       "      <td>0.519368</td>\n",
       "      <td>0.522598</td>\n",
       "      <td>0.524294</td>\n",
       "      <td>0.512212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.278084</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>-0.000348</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>0.470824</td>\n",
       "      <td>0.464162</td>\n",
       "      <td>0.457021</td>\n",
       "      <td>0.447772</td>\n",
       "      <td>0.444551</td>\n",
       "      <td>0.442531</td>\n",
       "      <td>0.443979</td>\n",
       "      <td>0.445125</td>\n",
       "      <td>0.456122</td>\n",
       "      <td>0.457975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>585 rows × 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ndvi_smooth_mean_28  ndvi_smooth_mean_29  ndvi_smooth_mean_30  \\\n",
       "0               0.492664             0.506519             0.514245   \n",
       "1               0.523357             0.511972             0.502959   \n",
       "2               0.479728             0.459045             0.450454   \n",
       "3               0.400038             0.397093             0.390670   \n",
       "4               0.354022             0.346084             0.339436   \n",
       "..                   ...                  ...                  ...   \n",
       "580             0.418890             0.403456             0.391616   \n",
       "581             0.413986             0.405636             0.403766   \n",
       "582             0.569267             0.571609             0.564436   \n",
       "583             0.556083             0.538577             0.521227   \n",
       "584             0.470824             0.464162             0.457021   \n",
       "\n",
       "     ndvi_smooth_mean_31  ndvi_smooth_mean_32  ndvi_smooth_mean_33  \\\n",
       "0               0.502695             0.492293             0.480777   \n",
       "1               0.499854             0.500775             0.498219   \n",
       "2               0.435791             0.426768             0.434232   \n",
       "3               0.385279             0.386711             0.390665   \n",
       "4               0.339607             0.347509             0.355982   \n",
       "..                   ...                  ...                  ...   \n",
       "580             0.388964             0.389758             0.392774   \n",
       "581             0.401218             0.400826             0.403209   \n",
       "582             0.559349             0.551364             0.547924   \n",
       "583             0.517825             0.516809             0.517540   \n",
       "584             0.447772             0.444551             0.442531   \n",
       "\n",
       "     ndvi_smooth_mean_34  ndvi_smooth_mean_35  ndvi_smooth_mean_36  \\\n",
       "0               0.470647             0.469949             0.470567   \n",
       "1               0.481144             0.452316             0.436442   \n",
       "2               0.443162             0.444332             0.418934   \n",
       "3               0.392255             0.377887             0.350932   \n",
       "4               0.364158             0.363430             0.349029   \n",
       "..                   ...                  ...                  ...   \n",
       "580             0.397628             0.399128             0.386335   \n",
       "581             0.403717             0.403379             0.400121   \n",
       "582             0.544081             0.542496             0.539937   \n",
       "583             0.519368             0.522598             0.524294   \n",
       "584             0.443979             0.445125             0.456122   \n",
       "\n",
       "     ndvi_smooth_mean_37  ...  ppt_week_sum_33_pro_curve_mean  \\\n",
       "0               0.470058  ...                       -0.000000   \n",
       "1               0.417638  ...                       -0.000814   \n",
       "2               0.410383  ...                       -0.000000   \n",
       "3               0.340456  ...                       -0.000965   \n",
       "4               0.329171  ...                       -0.000022   \n",
       "..                   ...  ...                             ...   \n",
       "580             0.361557  ...                        0.000002   \n",
       "581             0.393150  ...                        0.000018   \n",
       "582             0.541718  ...                        0.000000   \n",
       "583             0.512212  ...                        0.000000   \n",
       "584             0.457975  ...                        0.000000   \n",
       "\n",
       "     ppt_week_sum_33_plan_curve_mean  ppt_week_sum_34_slope_rad_mean_x  \\\n",
       "0                           0.000000                         -0.000000   \n",
       "1                           0.001208                         -0.000000   \n",
       "2                           0.000000                         -0.000000   \n",
       "3                           0.001431                         -0.272692   \n",
       "4                           0.000032                         -0.000000   \n",
       "..                               ...                               ...   \n",
       "580                        -0.000008                         -0.000000   \n",
       "581                        -0.000064                         -0.000000   \n",
       "582                        -0.000000                         -0.000000   \n",
       "583                        -0.000000                         -0.278084   \n",
       "584                        -0.000000                         -0.000000   \n",
       "\n",
       "     ppt_week_sum_34_slope_rad_mean_y  ppt_week_sum_34_pro_curve_mean  \\\n",
       "0                            0.000000                       -0.000000   \n",
       "1                            0.000000                       -0.000000   \n",
       "2                            0.000000                       -0.000000   \n",
       "3                            0.054842                       -0.000713   \n",
       "4                            0.000000                       -0.000000   \n",
       "..                                ...                             ...   \n",
       "580                          0.000000                        0.000000   \n",
       "581                          0.000000                        0.000000   \n",
       "582                          0.000000                        0.000000   \n",
       "583                          0.001886                        0.000095   \n",
       "584                          0.000000                        0.000000   \n",
       "\n",
       "     ppt_week_sum_34_plan_curve_mean  ppt_week_sum_35_slope_rad_mean_x  \\\n",
       "0                           0.000000                         -0.000000   \n",
       "1                           0.000000                         -0.000000   \n",
       "2                           0.000000                         -0.066582   \n",
       "3                           0.001058                         -0.000000   \n",
       "4                           0.000000                         -0.000000   \n",
       "..                               ...                               ...   \n",
       "580                        -0.000000                         -0.000000   \n",
       "581                        -0.000000                         -0.000000   \n",
       "582                        -0.000000                         -0.000000   \n",
       "583                        -0.000348                         -0.000000   \n",
       "584                        -0.000000                         -0.000000   \n",
       "\n",
       "     ppt_week_sum_35_slope_rad_mean_y  ppt_week_sum_35_pro_curve_mean  \\\n",
       "0                             0.00000                       -0.000000   \n",
       "1                             0.00000                       -0.000000   \n",
       "2                             0.01339                       -0.000174   \n",
       "3                             0.00000                       -0.000000   \n",
       "4                             0.00000                       -0.000000   \n",
       "..                                ...                             ...   \n",
       "580                           0.00000                        0.000000   \n",
       "581                           0.00000                        0.000000   \n",
       "582                           0.00000                        0.000000   \n",
       "583                           0.00000                        0.000000   \n",
       "584                           0.00000                        0.000000   \n",
       "\n",
       "     ppt_week_sum_35_plan_curve_mean  \n",
       "0                           0.000000  \n",
       "1                           0.000000  \n",
       "2                           0.000258  \n",
       "3                           0.000000  \n",
       "4                           0.000000  \n",
       "..                               ...  \n",
       "580                        -0.000000  \n",
       "581                        -0.000000  \n",
       "582                        -0.000000  \n",
       "583                        -0.000000  \n",
       "584                        -0.000000  \n",
       "\n",
       "[585 rows x 231 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_path = os.path.join(data_dir, 'df_ndvi_rendvi.pkl')\n",
    "df = pd.read_pickle(df_path)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb1721a3-da31-4b16-84fe-27edfee091bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Identify leakage columns ---\n",
    "leakage_cols = [col for col in df.columns if any(\n",
    "    col.endswith(f\"_{m}\") for m in range(36,45)\n",
    ")]\n",
    "leakage_cols.extend([col for col in df.columns if col.endswith('length')])\n",
    "leakage_cols.extend([col for col in df.columns if 'mcari2' in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6ff2fce-c60a-4612-a85c-0b0f93c1fd00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Define target and features ---\n",
    "target_cols = [\n",
    "    \n",
    "    \n",
    "    \n",
    "    'ndvi_smooth_mean_28',\n",
    "    'ndvi_smooth_mean_29',\n",
    "    'ndvi_smooth_mean_30',\n",
    "    'ndvi_smooth_mean_31',\n",
    "    'ndvi_smooth_mean_32',\n",
    "    'ndvi_smooth_mean_33',\n",
    "    'ndvi_smooth_mean_34',\n",
    "    'ndvi_smooth_mean_35',\n",
    "    'ndvi_smooth_mean_36',\n",
    "    'ndvi_smooth_mean_37',\n",
    "    'ndvi_smooth_mean_38',\n",
    "    'ndvi_smooth_mean_39',\n",
    "    'ndvi_smooth_mean_40',\n",
    "    'ndvi_smooth_mean_41',\n",
    "    'ndvi_smooth_mean_42',\n",
    "    'ndvi_smooth_mean_43',\n",
    "    'ndvi_smooth_mean_44',\n",
    "    \n",
    "    'rendvi_smooth_mean_28',\n",
    "    'rendvi_smooth_mean_29',\n",
    "    'rendvi_smooth_mean_30',\n",
    "    'rendvi_smooth_mean_31',\n",
    "    'rendvi_smooth_mean_32',\n",
    "    'rendvi_smooth_mean_33',\n",
    "    'rendvi_smooth_mean_34',\n",
    "    'rendvi_smooth_mean_35',\n",
    "    'rendvi_smooth_mean_36',\n",
    "    'rendvi_smooth_mean_37',\n",
    "    'rendvi_smooth_mean_38',\n",
    "    'rendvi_smooth_mean_39',\n",
    "    'rendvi_smooth_mean_40',\n",
    "    'rendvi_smooth_mean_41',\n",
    "    'rendvi_smooth_mean_42',\n",
    "    'rendvi_smooth_mean_43',\n",
    "    'rendvi_smooth_mean_44',\n",
    "]\n",
    "X = df.drop(columns=leakage_cols + ['plot_id', 'year'] + target_cols)\n",
    "y = df[target_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "097e5473-13ee-4f4e-8c7d-e48568cc6e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 175)\n",
      "(117, 175)\n",
      "(117, 175)\n",
      "(351, 18)\n",
      "(117, 18)\n",
      "(117, 18)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_test, X_hold, y_test, y_hold = train_test_split(\n",
    "    X, y, test_size = 0.8, random_state = 42\n",
    ")\n",
    "\n",
    "X_train, X_tune, y_train, y_tune = train_test_split(\n",
    "    X_hold, y_hold, test_size = 0.25, random_state = 42\n",
    ")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_tune.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_tune.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff80204-3795-4a92-be7b-5b3fd84c5b5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 11:08:28.383306: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-23 11:08:28.458554: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-23 11:08:29.981717: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 11:08:30.192974: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Fold 1 train R² = 0.848 | val R² = 0.824\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Fold 2 train R² = 0.834 | val R² = 0.807\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Fold 3 train R² = 0.846 | val R² = 0.836\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Fold 4 train R² = 0.843 | val R² = 0.805\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Fold 5 train R² = 0.847 | val R² = 0.815\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "=== CV Summary ===\n",
      "Train R² mean ± std: 0.8436143469058097 ± 0.004981372299037353\n",
      "Val R² mean ± std: 0.8173386301737595 ± 0.011337116595240037\n",
      "Target 00 mean CV R² = 0.918\n",
      "Target 01 mean CV R² = 0.925\n",
      "Target 02 mean CV R² = 0.917\n",
      "Target 03 mean CV R² = 0.884\n",
      "Target 04 mean CV R² = 0.880\n",
      "Target 05 mean CV R² = 0.839\n",
      "Target 06 mean CV R² = 0.783\n",
      "Target 07 mean CV R² = 0.723\n",
      "Target 08 mean CV R² = 0.644\n",
      "Target 09 mean CV R² = 0.900\n",
      "Target 10 mean CV R² = 0.894\n",
      "Target 11 mean CV R² = 0.876\n",
      "Target 12 mean CV R² = 0.853\n",
      "Target 13 mean CV R² = 0.842\n",
      "Target 14 mean CV R² = 0.808\n",
      "Target 15 mean CV R² = 0.755\n",
      "Target 16 mean CV R² = 0.664\n",
      "Target 17 mean CV R² = 0.607\n",
      "\n",
      "=== Final Tune Set Performance ===\n",
      "Tune set R² = 0.811 | RMSE = 0.001245\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# -----------------------------\n",
    "# Scale features\n",
    "# -----------------------------\n",
    "scaler_X = MinMaxScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_tune_scaled = scaler_X.transform(X_tune)  # tune set\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_tune_scaled = scaler_y.transform(y_tune)  # tune set\n",
    "\n",
    "# -----------------------------\n",
    "# CV setup\n",
    "# -----------------------------\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=8536907)\n",
    "\n",
    "train_r2s = []\n",
    "val_r2s = []\n",
    "per_target_val = []\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]\n",
    "epochs = 500\n",
    "batch_size = 32\n",
    "\n",
    "# -----------------------------\n",
    "# CV loop on training set\n",
    "# -----------------------------\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X_train_scaled)):\n",
    "    print(f\"\\n--- Fold {fold+1}/{n_splits} ---\")\n",
    "    \n",
    "    X_tr, X_val_fold = X_train_scaled[tr_idx], X_train_scaled[val_idx]\n",
    "    y_tr, y_val_fold = y_train_scaled[tr_idx], y_train_scaled[val_idx]\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(input_dim,)),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.1), \n",
    "        tf.keras.layers.Dense(12, activation='relu'),\n",
    "        tf.keras.layers.Dense(8, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.1),     \n",
    "        tf.keras.layers.Dense(output_dim, activation='linear')\n",
    "        \n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='mse')\n",
    "    \n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=20, restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        validation_data=(X_val_fold, y_val_fold),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "    \n",
    "    # -----------------------------\n",
    "    # Train / validation R² per fold\n",
    "    # -----------------------------\n",
    "    y_tr_pred = scaler_y.inverse_transform(model.predict(X_tr))\n",
    "    y_val_pred = scaler_y.inverse_transform(model.predict(X_val_fold))\n",
    "    \n",
    "    y_tr_orig = scaler_y.inverse_transform(y_tr)\n",
    "    y_val_orig = scaler_y.inverse_transform(y_val_fold)\n",
    "    \n",
    "    train_r2 = np.mean([r2_score(y_tr_orig[:, j], y_tr_pred[:, j])\n",
    "                        for j in range(output_dim)])\n",
    "    val_r2 = np.mean([r2_score(y_val_orig[:, j], y_val_pred[:, j])\n",
    "                      for j in range(output_dim)])\n",
    "    \n",
    "    train_r2s.append(train_r2)\n",
    "    val_r2s.append(val_r2)\n",
    "    per_target_val.append([r2_score(y_val_orig[:, j], y_val_pred[:, j])\n",
    "                           for j in range(output_dim)])\n",
    "    \n",
    "    print(f\"Fold {fold+1} train R² = {train_r2:.3f} | val R² = {val_r2:.3f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Final model trained on full train set\n",
    "# -----------------------------\n",
    "final_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(input_dim,)),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.1), \n",
    "        tf.keras.layers.Dense(12, activation='relu'),\n",
    "        tf.keras.layers.Dense(8, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.1),     \n",
    "        tf.keras.layers.Dense(output_dim, activation='linear')\n",
    "        \n",
    "    ])\n",
    "final_model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='mse')\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, restore_best_weights=True\n",
    ")\n",
    "\n",
    "final_model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    validation_data=(X_tune_scaled, y_tune_scaled),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=0,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Final prediction on tune\n",
    "# -----------------------------\n",
    "y_tune_pred = scaler_y.inverse_transform(final_model.predict(X_tune_scaled))\n",
    "\n",
    "tune_r2 = np.mean([r2_score(y_tune.iloc[:, j], y_tune_pred[:, j])\n",
    "                   for j in range(output_dim)])\n",
    "tune_rmse = np.mean([mean_squared_error(y_tune.iloc[:, j], y_tune_pred[:, j])\n",
    "                     for j in range(output_dim)])\n",
    "\n",
    "print(\"\\n=== CV Summary ===\")\n",
    "per_target_val = np.array(per_target_val)\n",
    "print(\"Train R² mean ± std:\", np.mean(train_r2s), \"±\", np.std(train_r2s))\n",
    "print(\"Val R² mean ± std:\", np.mean(val_r2s), \"±\", np.std(val_r2s))\n",
    "for j in range(output_dim):\n",
    "    print(f\"Target {j:02d} mean CV R² = {per_target_val[:, j].mean():.3f}\")\n",
    "\n",
    "print(\"\\n=== Final Tune Set Performance ===\")\n",
    "print(f\"Tune set R² = {tune_r2:.3f} | RMSE = {tune_rmse:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad9f90cc-5009-4510-8fce-e1c9cd75b613",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_787551/1527486593.py:11: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = cm.get_cmap('coolwarm', n_weeks)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import numpy as np\n",
    "\n",
    "# Define weeks\n",
    "weeks = range(36, 45)  # 36–44\n",
    "n_weeks = len(weeks)\n",
    "\n",
    "# Colormap\n",
    "cmap = cm.get_cmap('coolwarm', n_weeks)\n",
    "norm = plt.Normalize(vmin=0, vmax=n_weeks - 1)\n",
    "\n",
    "# Predictions and observations\n",
    "y_tune_pred_inv = scaler_y.inverse_transform(final_model.predict(X_tune_scaled))\n",
    "y_tune_obs_inv = y_tune.values  # already in original scale\n",
    "\n",
    "# -----------------------------\n",
    "# Setup plot\n",
    "# -----------------------------\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sc = ax.scatter([], [], s=50)\n",
    "line, = ax.plot([], [], 'k--')\n",
    "ax.set_xlim(y_tune_obs_inv.min()-0.02, y_tune_obs_inv.max()+0.02)\n",
    "ax.set_ylim(y_tune_obs_inv.min()-0.02, y_tune_obs_inv.max()+0.02)\n",
    "ax.set_xlabel(\"Observed NDVI\")\n",
    "ax.set_ylabel(\"Predicted NDVI\")\n",
    "ax.set_title(\"Predicted vs Observed NDVI by Week (Tune Set)\")\n",
    "\n",
    "# -----------------------------\n",
    "# Animation function\n",
    "# -----------------------------\n",
    "def update(frame):\n",
    "    ax.clear()\n",
    "    i = frame\n",
    "    color = cmap(norm(i))\n",
    "    ax.scatter(y_tune_obs_inv[:, i], y_tune_pred_inv[:, i], color=color, s=50, alpha=0.7)\n",
    "    ax.plot([y_tune_obs_inv.min()-0.02, y_tune_obs_inv.max()+0.02],\n",
    "            [y_tune_obs_inv.min()-0.02, y_tune_obs_inv.max()+0.02], 'k--')\n",
    "    ax.set_xlabel(\"Observed NDVI\")\n",
    "    ax.set_ylabel(\"Predicted NDVI\")\n",
    "    ax.set_title(f\"Week {weeks[i]}: Predicted vs Observed NDVI\")\n",
    "    return ax,\n",
    "\n",
    "# -----------------------------\n",
    "# Create animation\n",
    "# -----------------------------\n",
    "anim = FuncAnimation(fig, update, frames=n_weeks, blit=False, repeat=True)\n",
    "\n",
    "# Save as GIF\n",
    "writer = PillowWriter(fps=1)  # 1 frame per second\n",
    "anim.save(\"tune_set_ndvi_by_week.gif\", writer=writer)\n",
    "\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df18ea99-34e5-411b-9620-b2ea0521df2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# import tensorflow as tf\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# # -----------------------------\n",
    "# # Parameters\n",
    "# # -----------------------------\n",
    "# n_splits = 5\n",
    "# input_dim = X.shape[1]\n",
    "# output_dim = y.shape[1]\n",
    "# epochs = 500\n",
    "# batch_size = 32\n",
    "\n",
    "# # -----------------------------\n",
    "# # Scale features and targets\n",
    "# # -----------------------------\n",
    "# scaler_X = MinMaxScaler()\n",
    "# X_scaled = scaler_X.fit_transform(X_train)\n",
    "\n",
    "# scaler_y = MinMaxScaler()\n",
    "# y_scaled = scaler_y.fit_transform(y_train)\n",
    "\n",
    "# # -----------------------------\n",
    "# # Cross-validation setup\n",
    "# # -----------------------------\n",
    "# kf = KFold(n_splits=n_splits, shuffle=True, random_state=8536907)\n",
    "\n",
    "# train_r2s = []\n",
    "# val_r2s = []\n",
    "# per_target_val = []\n",
    "\n",
    "# # -----------------------------\n",
    "# # CV Loop\n",
    "# # -----------------------------\n",
    "# for fold, (tr_idx, val_idx) in enumerate(kf.split(X_scaled)):\n",
    "#     print(f\"\\n--- Fold {fold+1}/{n_splits} ---\")\n",
    "    \n",
    "#     X_tr, X_val_fold = X_scaled[tr_idx], X_scaled[val_idx]\n",
    "#     y_tr, y_val_fold = y_scaled[tr_idx], y_scaled[val_idx]\n",
    "    \n",
    "#     # -----------------------------\n",
    "#     # Build small NN\n",
    "#     # -----------------------------\n",
    "#     model = tf.keras.Sequential([\n",
    "#         tf.keras.layers.Input(shape=(input_dim,)),\n",
    "#         tf.keras.layers.Dense(16, activation='relu'),\n",
    "#         tf.keras.layers.Dense(12, activation='relu'),\n",
    "#         tf.keras.layers.Dense(8, activation='relu'),\n",
    "#         tf.keras.layers.Dense(output_dim, activation='linear')\n",
    "#     ])\n",
    "    \n",
    "#     model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "#                   loss='mse')\n",
    "    \n",
    "#     # Early stopping to prevent overfitting\n",
    "#     early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "#         monitor='val_loss', patience=20, restore_best_weights=True\n",
    "#     )\n",
    "    \n",
    "#     # Fit model\n",
    "#     history = model.fit(\n",
    "#         X_tr, y_tr,\n",
    "#         validation_data=(X_val_fold, y_val_fold),\n",
    "#         epochs=epochs,\n",
    "#         batch_size=batch_size,\n",
    "#         verbose=0,\n",
    "#         callbacks=[early_stop]\n",
    "#     )\n",
    "    \n",
    "#     # -----------------------------\n",
    "#     # Predict and inverse-transform\n",
    "#     # -----------------------------\n",
    "#     y_tr_pred = scaler_y.inverse_transform(model.predict(X_tr))\n",
    "#     y_val_pred = scaler_y.inverse_transform(model.predict(X_val_fold))\n",
    "    \n",
    "#     y_tr_orig = scaler_y.inverse_transform(y_tr)\n",
    "#     y_val_orig = scaler_y.inverse_transform(y_val_fold)\n",
    "    \n",
    "#     # -----------------------------\n",
    "#     # Compute R²\n",
    "#     # -----------------------------\n",
    "#     train_r2 = np.mean([r2_score(y_tr_orig[:, j], y_tr_pred[:, j])\n",
    "#                         for j in range(output_dim)])\n",
    "#     val_r2 = np.mean([r2_score(y_val_orig[:, j], y_val_pred[:, j])\n",
    "#                       for j in range(output_dim)])\n",
    "    \n",
    "#     train_r2s.append(train_r2)\n",
    "#     val_r2s.append(val_r2)\n",
    "    \n",
    "#     per_target_val.append([r2_score(y_val_orig[:, j], y_val_pred[:, j])\n",
    "#                            for j in range(output_dim)])\n",
    "    \n",
    "#     print(f\"Fold {fold+1} train R² = {train_r2:.3f} | val R² = {val_r2:.3f}\")\n",
    "\n",
    "# # -----------------------------\n",
    "# # CV Summary\n",
    "# # -----------------------------\n",
    "# per_target_val = np.array(per_target_val)\n",
    "# print(\"\\n=== CV Summary ===\")\n",
    "# print(\"Train R² mean ± std:\", np.mean(train_r2s), \"±\", np.std(train_r2s))\n",
    "# print(\"Val R² mean ± std:\", np.mean(val_r2s), \"±\", np.std(val_r2s))\n",
    "\n",
    "# for j in range(output_dim):\n",
    "#     print(f\"Target {j:02d} mean R² = {per_target_val[:, j].mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17ff17-6933-4e6b-9473-ccef77a0806f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python GrapeExpectationsML",
   "language": "python",
   "name": "grapeexpectationsml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
